{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96ed2698",
   "metadata": {},
   "source": [
    "Preparação para o Active Learning\n",
    "\n",
    "Será considerado o cenário simulado onde temos um pool de $5.240$ lesões, mas apenas uma pequena parte delas está rotulada com o diagnóstico final.\n",
    "\n",
    "Separação do Pool Inicial Rotulado: Início com apenas $5\\%$ ($262$ lesões) aleatórias do seu df_final como seu conjunto Initial Labeled Set ($L_0$).\n",
    "\n",
    "Pool Não Rotulado: O restante ($4.978$ lesões) é o Unlabeled Pool ($U$).\n",
    "\n",
    "Próximos passos:\n",
    "\n",
    "Desenvolvimento do Modelo: Defina a arquitetura da CNN (usando as imagens) e um método para incorporar os dados MONET_... (por exemplo, como side information ou como um passo inicial de pré-classificação).\n",
    "\n",
    "Estratégia de Aquisição (O cerne do Active Learning): Defina como você usará os dados MONET_... para selecionar as próximas $X$ amostras do pool $U$ a serem rotuladas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c9c07",
   "metadata": {},
   "source": [
    "## Adaptação para treino ASSL\n",
    "#### 1 - Separação em conjuntos L (rotulado) e U (não rotulado)\n",
    "- L: contém imagens com rótulos verdadeiros (serão usadas na perda supervisionada).\n",
    "\n",
    "- U: contém imagens sem rótulos (usadas na perda não supervisionada e no cálculo das métricas por amostra).\n",
    "Durante o treinamento ativo, novas amostras de U podem ser movidas para L conforme forem selecionadas (Top-K com maior Score).\n",
    "\n",
    "#### 2 - Augmentations: aumentos, incrementos ou ampliações de modo geral. já temos um tratamento realizado para utilizar as imagens do dataset no Keras. O artigo cita dois tipos de transformações:\n",
    "\n",
    "O objetivo é gerar versões diferentes da mesma imagem para medir consistência.\n",
    "\n",
    "Weak augmentation: transformações leves (flip, crop, normalize). Mantém a semântica da imagem.\n",
    "→ Usada para gerar o pseudo-rótulo confiável.\n",
    "\n",
    "Strong augmentation: transformações mais intensas (RandAugment ou CTAugment).\n",
    "→ Usada para verificar se o modelo é consistente ao prever a mesma classe mesmo sob distorções.\n",
    "\n",
    "Essas duas versões da imagem são processadas juntas em FixMatch.\n",
    "\n",
    "#### FixMatch\n",
    "Método de aprendizado semi-supervisionado que combina consistência e pseudo-rotulagem:\n",
    "\n",
    "O modelo gera uma predição para a imagem weak.\n",
    "\n",
    "Se a probabilidade máxima for ≥ τ (ex.: 0.95), essa classe vira o pseudo-rótulo.\n",
    "\n",
    "A imagem strong é usada para calcular uma perda não supervisionada (cross-entropy entre o pseudo-rótulo e a predição da versão strong).\n",
    "Isso permite treinar com imagens não rotuladas usando apenas as predições mais confiantes.\n",
    "\n",
    "Obs: As Random layers* do Keras se aproximam da ideia do FixMatch\n",
    "\n",
    "3 - Estruturas para EMA + UCB\n",
    "EMA (Exponential Moving Average)\n",
    "\n",
    "Técnica que mantém uma média suavizada ao longo do tempo.\n",
    "Serve para reduzir flutuações bruscas na incerteza de uma amostra.\n",
    "Fórmula:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "onde α é a taxa de atualização (geralmente 0.8).\n",
    "\n",
    "UCB (Upper Confidence Bound)\n",
    "\n",
    "Usada para ponderar média + variância de uma métrica, originada do reinforcement learning.\n",
    "Ela favorece amostras com alta incerteza ou alta variação (potencialmente informativas).\n",
    "\n",
    "\n",
    "\t​\n",
    "\n",
    "\n",
    "onde c controla o grau de exploração (típico: 0.5 para incerteza e 2.0 para inconsistência).\n",
    "\n",
    "Essas estruturas são aplicadas tanto à incerteza quanto à inconsistência de cada amostra U.\n",
    "Precisamos de um ID por amostra em U para acumular EMA/UCB corretamente. Se seu train_dataset já é tf.data.Dataset\n",
    "\n",
    "#### 4 - Definir métricas por amostra\n",
    "\n",
    "Pseudo-EL2N: \n",
    "\n",
    "KL simétrica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from config import H, W, NUM_CLASSES\n",
    "\n",
    "# as imagens são definidas como image_size=(180, 180) na divisão do dataset pro tensorflow\n",
    "\n",
    "INPUT_SHAPE = (H, W, 3)  # defina H,W conforme seu dataset\n",
    "\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=INPUT_SHAPE),\n",
    "        layers.Rescaling(1./255),\n",
    "        layers.Conv2D(32, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(NUM_CLASSES)  # logits\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "optimizer = keras.optimizers.Adam()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
